{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Main'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''Data Visualizations'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Data preparations'''\n",
    "from sklearn import preprocessing as pp\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Algorithms'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire data\n",
    "current_path = os.getcwd()\n",
    "file = '\\\\datasets\\\\credit_card_data\\\\credit_card.csv'\n",
    "data = pd.read_csv(current_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fraudlulent transactions: 492\n"
     ]
    }
   ],
   "source": [
    "print('Number of fraudlulent transactions:', data['Class'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanCounter = np.isnan(data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinctCounter = data.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      124592\n",
       "V1        275663\n",
       "V2        275663\n",
       "V3        275663\n",
       "V4        275663\n",
       "V5        275663\n",
       "V6        275663\n",
       "V7        275663\n",
       "V8        275663\n",
       "V9        275663\n",
       "V10       275663\n",
       "V11       275663\n",
       "V12       275663\n",
       "V13       275663\n",
       "V14       275663\n",
       "V15       275663\n",
       "V16       275663\n",
       "V17       275663\n",
       "V18       275663\n",
       "V19       275663\n",
       "V20       275663\n",
       "V21       275663\n",
       "V22       275663\n",
       "V23       275663\n",
       "V24       275663\n",
       "V25       275663\n",
       "V26       275663\n",
       "V27       275663\n",
       "V28       275663\n",
       "Amount     32767\n",
       "Class          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinctCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature matrix and labels array\n",
    "dataX = data.copy().drop(['Class'], axis=1)\n",
    "dataY = data['Class'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "featuresToScale = dataX.drop(['Time'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresToScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sX = pp.StandardScaler(copy=True)\n",
    "dataX.loc[:, featuresToScale] = sX.fit_transform(dataX[featuresToScale])\n",
    "scalingFactors = pd.DataFrame(data=[sX.mean_, sX.scale_], index=['Mean', 'StDev'], columns=featuresToScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>-8.881566e-18</td>\n",
       "      <td>-1.277349e-17</td>\n",
       "      <td>-4.790058e-17</td>\n",
       "      <td>-1.955940e-17</td>\n",
       "      <td>3.832046e-17</td>\n",
       "      <td>9.979288e-18</td>\n",
       "      <td>1.476935e-17</td>\n",
       "      <td>3.293165e-18</td>\n",
       "      <td>9.979288e-20</td>\n",
       "      <td>5.289022e-18</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.035398e-18</td>\n",
       "      <td>-4.989644e-19</td>\n",
       "      <td>2.794201e-18</td>\n",
       "      <td>9.380530e-18</td>\n",
       "      <td>1.117680e-17</td>\n",
       "      <td>-5.109395e-17</td>\n",
       "      <td>7.946008e-18</td>\n",
       "      <td>1.234937e-18</td>\n",
       "      <td>-6.336848e-18</td>\n",
       "      <td>2.913952e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StDev</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "Mean  -8.881566e-18 -1.277349e-17 -4.790058e-17 -1.955940e-17  3.832046e-17   \n",
       "StDev  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "Mean   9.979288e-18  1.476935e-17  3.293165e-18  9.979288e-20  5.289022e-18   \n",
       "StDev  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "           ...                V20           V21           V22           V23  \\\n",
       "Mean       ...      -7.035398e-18 -4.989644e-19  2.794201e-18  9.380530e-18   \n",
       "StDev      ...       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "Mean   1.117680e-17 -5.109395e-17  7.946008e-18  1.234937e-18 -6.336848e-18   \n",
       "StDev  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "             Amount  \n",
       "Mean   2.913952e-17  \n",
       "StDev  1.000000e+00  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalingFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>-8.156865e-16</td>\n",
       "      <td>5.446990e-17</td>\n",
       "      <td>-4.351870e-15</td>\n",
       "      <td>-6.716848e-16</td>\n",
       "      <td>-2.425072e-16</td>\n",
       "      <td>4.028970e-16</td>\n",
       "      <td>-8.959599e-16</td>\n",
       "      <td>-2.346193e-16</td>\n",
       "      <td>2.962026e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>2.740067e-16</td>\n",
       "      <td>3.505049e-17</td>\n",
       "      <td>1.478472e-15</td>\n",
       "      <td>-6.797571e-16</td>\n",
       "      <td>1.088237e-16</td>\n",
       "      <td>-7.317987e-16</td>\n",
       "      <td>3.247603e-16</td>\n",
       "      <td>-2.953498e-18</td>\n",
       "      <td>5.401574e-17</td>\n",
       "      <td>2.727008e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.879855e+01</td>\n",
       "      <td>-4.403529e+01</td>\n",
       "      <td>-3.187173e+01</td>\n",
       "      <td>-4.013919e+00</td>\n",
       "      <td>-8.240810e+01</td>\n",
       "      <td>-1.963606e+01</td>\n",
       "      <td>-3.520940e+01</td>\n",
       "      <td>-6.130252e+01</td>\n",
       "      <td>-1.222802e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.069146e+01</td>\n",
       "      <td>-4.741907e+01</td>\n",
       "      <td>-1.506565e+01</td>\n",
       "      <td>-7.175446e+01</td>\n",
       "      <td>-4.683638e+00</td>\n",
       "      <td>-1.975033e+01</td>\n",
       "      <td>-5.401098e+00</td>\n",
       "      <td>-5.590660e+01</td>\n",
       "      <td>-4.674612e+01</td>\n",
       "      <td>-3.532294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-4.698918e-01</td>\n",
       "      <td>-3.624707e-01</td>\n",
       "      <td>-5.872142e-01</td>\n",
       "      <td>-5.993788e-01</td>\n",
       "      <td>-5.010686e-01</td>\n",
       "      <td>-5.766822e-01</td>\n",
       "      <td>-4.478860e-01</td>\n",
       "      <td>-1.746805e-01</td>\n",
       "      <td>-5.853631e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.746334e-01</td>\n",
       "      <td>-3.109433e-01</td>\n",
       "      <td>-7.473476e-01</td>\n",
       "      <td>-2.591784e-01</td>\n",
       "      <td>-5.854676e-01</td>\n",
       "      <td>-6.084001e-01</td>\n",
       "      <td>-6.780717e-01</td>\n",
       "      <td>-1.755053e-01</td>\n",
       "      <td>-1.604440e-01</td>\n",
       "      <td>-3.308401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>9.245351e-03</td>\n",
       "      <td>3.965683e-02</td>\n",
       "      <td>1.186124e-01</td>\n",
       "      <td>-1.401724e-02</td>\n",
       "      <td>-3.936682e-02</td>\n",
       "      <td>-2.058046e-01</td>\n",
       "      <td>3.241723e-02</td>\n",
       "      <td>1.871982e-02</td>\n",
       "      <td>-4.681169e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.104705e-02</td>\n",
       "      <td>-4.009429e-02</td>\n",
       "      <td>9.345377e-03</td>\n",
       "      <td>-1.792420e-02</td>\n",
       "      <td>6.765678e-02</td>\n",
       "      <td>3.183240e-02</td>\n",
       "      <td>-1.081217e-01</td>\n",
       "      <td>3.325174e-03</td>\n",
       "      <td>3.406368e-02</td>\n",
       "      <td>-2.652715e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>6.716939e-01</td>\n",
       "      <td>4.867202e-01</td>\n",
       "      <td>6.774569e-01</td>\n",
       "      <td>5.250082e-01</td>\n",
       "      <td>4.433465e-01</td>\n",
       "      <td>2.991625e-01</td>\n",
       "      <td>4.611107e-01</td>\n",
       "      <td>2.740785e-01</td>\n",
       "      <td>5.435305e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.725733e-01</td>\n",
       "      <td>2.537392e-01</td>\n",
       "      <td>7.283360e-01</td>\n",
       "      <td>2.364319e-01</td>\n",
       "      <td>7.257153e-01</td>\n",
       "      <td>6.728006e-01</td>\n",
       "      <td>4.996663e-01</td>\n",
       "      <td>2.255648e-01</td>\n",
       "      <td>2.371526e-01</td>\n",
       "      <td>-4.471707e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>1.253351e+00</td>\n",
       "      <td>1.335775e+01</td>\n",
       "      <td>6.187993e+00</td>\n",
       "      <td>1.191874e+01</td>\n",
       "      <td>2.521413e+01</td>\n",
       "      <td>5.502015e+01</td>\n",
       "      <td>9.747824e+01</td>\n",
       "      <td>1.675153e+01</td>\n",
       "      <td>1.419494e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.113464e+01</td>\n",
       "      <td>3.703471e+01</td>\n",
       "      <td>1.447304e+01</td>\n",
       "      <td>3.607668e+01</td>\n",
       "      <td>7.569684e+00</td>\n",
       "      <td>1.442532e+01</td>\n",
       "      <td>7.293975e+00</td>\n",
       "      <td>7.831940e+01</td>\n",
       "      <td>1.025434e+02</td>\n",
       "      <td>1.023622e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575 -8.156865e-16  5.446990e-17 -4.351870e-15 -6.716848e-16   \n",
       "std     47488.145955  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min         0.000000 -2.879855e+01 -4.403529e+01 -3.187173e+01 -4.013919e+00   \n",
       "25%     54201.500000 -4.698918e-01 -3.624707e-01 -5.872142e-01 -5.993788e-01   \n",
       "50%     84692.000000  9.245351e-03  3.965683e-02  1.186124e-01 -1.401724e-02   \n",
       "75%    139320.500000  6.716939e-01  4.867202e-01  6.774569e-01  5.250082e-01   \n",
       "max    172792.000000  1.253351e+00  1.335775e+01  6.187993e+00  1.191874e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -2.425072e-16  4.028970e-16 -8.959599e-16 -2.346193e-16  2.962026e-16   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -8.240810e+01 -1.963606e+01 -3.520940e+01 -6.130252e+01 -1.222802e+01   \n",
       "25%   -5.010686e-01 -5.766822e-01 -4.478860e-01 -1.746805e-01 -5.853631e-01   \n",
       "50%   -3.936682e-02 -2.058046e-01  3.241723e-02  1.871982e-02 -4.681169e-02   \n",
       "75%    4.433465e-01  2.991625e-01  4.611107e-01  2.740785e-01  5.435305e-01   \n",
       "max    2.521413e+01  5.502015e+01  9.747824e+01  1.675153e+01  1.419494e+01   \n",
       "\n",
       "           ...                V20           V21           V22           V23  \\\n",
       "count      ...       2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...       2.740067e-16  3.505049e-17  1.478472e-15 -6.797571e-16   \n",
       "std        ...       1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min        ...      -7.069146e+01 -4.741907e+01 -1.506565e+01 -7.175446e+01   \n",
       "25%        ...      -2.746334e-01 -3.109433e-01 -7.473476e-01 -2.591784e-01   \n",
       "50%        ...      -8.104705e-02 -4.009429e-02  9.345377e-03 -1.792420e-02   \n",
       "75%        ...       1.725733e-01  2.537392e-01  7.283360e-01  2.364319e-01   \n",
       "max        ...       5.113464e+01  3.703471e+01  1.447304e+01  3.607668e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.088237e-16 -7.317987e-16  3.247603e-16 -2.953498e-18  5.401574e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -4.683638e+00 -1.975033e+01 -5.401098e+00 -5.590660e+01 -4.674612e+01   \n",
       "25%   -5.854676e-01 -6.084001e-01 -6.780717e-01 -1.755053e-01 -1.604440e-01   \n",
       "50%    6.765678e-02  3.183240e-02 -1.081217e-01  3.325174e-03  3.406368e-02   \n",
       "75%    7.257153e-01  6.728006e-01  4.996663e-01  2.255648e-01  2.371526e-01   \n",
       "max    7.569684e+00  1.442532e+01  7.293975e+00  7.831940e+01  1.025434e+02   \n",
       "\n",
       "             Amount  \n",
       "count  2.848070e+05  \n",
       "mean   2.727008e-16  \n",
       "std    1.000002e+00  \n",
       "min   -3.532294e-01  \n",
       "25%   -3.308401e-01  \n",
       "50%   -2.652715e-01  \n",
       "75%   -4.471707e-02  \n",
       "max    1.023622e+02  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering ans Feature Selection\n",
    "\n",
    "Feature engineering helps the learning algorithm to extract a stronger signal from the data. It removes less relevant features and creates new features from the existing data.\n",
    "\n",
    "The credit card dataset does not have original features. It contains only the principal components derived from PCA.\n",
    "\n",
    "Feature selection is not necessary: the number of samples vastly outnumber the number of features (284k vs 30), thus, overfitting is less likely.\n",
    "\n",
    "Let's produce a correlation matrix to make sure that the features only slightly correlate to each other.\n",
    "\n",
    "### Check correlation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationMatrix = pd.DataFrame(data=[], index=dataX.columns, columns=dataX.columns)\n",
    "for i in dataX.columns:\n",
    "    for j in dataX.columns:\n",
    "        correlationMatrix.loc[i, j] = np.round(pearsonr(dataX.loc[:,i], dataX.loc[:, j])[0], 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationFile = '\\\\datasets\\\\credit_card_data\\\\correlationMatrix.csv'\n",
    "correlationMatrix.to_csv(current_path + correlationFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time    V1    V2    V3    V4    V5    V6    V7    V8    V9  ...    \\\n",
      "Time       1  0.12 -0.01 -0.42 -0.11  0.17 -0.06  0.08 -0.04 -0.01  ...     \n",
      "V1      0.12     1    -0    -0    -0     0     0     0    -0     0  ...     \n",
      "V2     -0.01    -0     1     0    -0     0     0    -0    -0    -0  ...     \n",
      "V3     -0.42    -0     0     1    -0    -0     0     0    -0     0  ...     \n",
      "V4     -0.11    -0    -0    -0     1    -0    -0    -0     0     0  ...     \n",
      "V5      0.17     0     0    -0    -0     1     0    -0     0     0  ...     \n",
      "V6     -0.06     0     0     0    -0     0     1    -0    -0    -0  ...     \n",
      "V7      0.08     0    -0     0    -0    -0    -0     1    -0     0  ...     \n",
      "V8     -0.04    -0    -0    -0     0     0    -0    -0     1     0  ...     \n",
      "V9     -0.01     0    -0     0     0     0    -0     0     0     1  ...     \n",
      "V10     0.03     0    -0     0    -0     0     0     0     0    -0  ...     \n",
      "V11    -0.25     0     0     0    -0     0     0    -0     0     0  ...     \n",
      "V12     0.12     0    -0     0    -0     0     0     0     0    -0  ...     \n",
      "V13    -0.07    -0    -0    -0     0    -0    -0    -0    -0     0  ...     \n",
      "V14     -0.1     0    -0     0    -0     0     0     0    -0     0  ...     \n",
      "V15    -0.18    -0     0    -0     0     0    -0    -0     0    -0  ...     \n",
      "V16     0.01     0     0     0    -0     0    -0     0     0    -0  ...     \n",
      "V17    -0.07    -0    -0     0    -0     0     0     0    -0     0  ...     \n",
      "V18     0.09     0     0     0    -0     0     0     0    -0     0  ...     \n",
      "V19     0.03     0     0     0    -0    -0     0    -0    -0     0  ...     \n",
      "V20    -0.05     0     0     0    -0    -0     0     0     0    -0  ...     \n",
      "V21     0.04    -0     0    -0    -0    -0    -0     0     0     0  ...     \n",
      "V22     0.14     0     0    -0     0     0    -0    -0     0    -0  ...     \n",
      "V23     0.05     0     0    -0     0     0     0    -0     0    -0  ...     \n",
      "V24    -0.02    -0    -0     0     0    -0    -0    -0    -0    -0  ...     \n",
      "V25    -0.23    -0     0     0     0    -0     0     0    -0     0  ...     \n",
      "V26    -0.04    -0     0    -0    -0     0    -0    -0     0    -0  ...     \n",
      "V27    -0.01     0    -0     0    -0     0    -0    -0     0    -0  ...     \n",
      "V28    -0.01     0    -0     0    -0    -0     0     0    -0     0  ...     \n",
      "Amount -0.01 -0.23 -0.53 -0.21   0.1 -0.39  0.22   0.4  -0.1 -0.04  ...     \n",
      "\n",
      "         V20   V21   V22   V23   V24   V25   V26   V27   V28 Amount  \n",
      "Time   -0.05  0.04  0.14  0.05 -0.02 -0.23 -0.04 -0.01 -0.01  -0.01  \n",
      "V1         0    -0     0     0    -0    -0    -0     0     0  -0.23  \n",
      "V2         0     0     0     0    -0     0     0    -0    -0  -0.53  \n",
      "V3         0    -0    -0    -0     0     0    -0     0     0  -0.21  \n",
      "V4        -0    -0     0     0     0     0    -0    -0    -0    0.1  \n",
      "V5        -0    -0     0     0    -0    -0     0     0    -0  -0.39  \n",
      "V6         0    -0    -0     0    -0     0    -0    -0     0   0.22  \n",
      "V7         0     0    -0    -0    -0     0    -0    -0     0    0.4  \n",
      "V8         0     0     0     0    -0    -0     0     0    -0   -0.1  \n",
      "V9        -0     0    -0    -0    -0     0    -0    -0     0  -0.04  \n",
      "V10       -0     0    -0     0    -0    -0    -0    -0     0   -0.1  \n",
      "V11       -0     0     0     0     0    -0    -0    -0    -0      0  \n",
      "V12        0     0    -0     0     0    -0     0    -0     0  -0.01  \n",
      "V13        0     0    -0    -0    -0    -0    -0    -0     0   0.01  \n",
      "V14       -0    -0     0     0     0    -0    -0     0     0   0.03  \n",
      "V15        0     0    -0     0    -0     0     0    -0    -0     -0  \n",
      "V16        0    -0     0     0    -0    -0    -0     0     0     -0  \n",
      "V17       -0    -0    -0     0    -0     0     0     0    -0   0.01  \n",
      "V18       -0    -0    -0    -0    -0    -0     0     0     0   0.04  \n",
      "V19        0     0    -0     0    -0     0     0    -0    -0  -0.06  \n",
      "V20        1    -0     0     0     0     0    -0    -0    -0   0.34  \n",
      "V21       -0     1     0     0     0    -0    -0    -0     0   0.11  \n",
      "V22        0     0     1     0     0    -0    -0     0    -0  -0.06  \n",
      "V23        0     0     0     1     0    -0     0     0     0  -0.11  \n",
      "V24        0     0     0     0     1     0     0    -0    -0   0.01  \n",
      "V25        0    -0    -0    -0     0     1     0    -0     0  -0.05  \n",
      "V26       -0    -0    -0     0     0     0     1    -0    -0     -0  \n",
      "V27       -0    -0     0     0    -0    -0    -0     1     0   0.03  \n",
      "V28       -0     0    -0     0    -0     0    -0     0     1   0.01  \n",
      "Amount  0.34  0.11 -0.06 -0.11  0.01 -0.05    -0  0.03  0.01      1  \n",
      "\n",
      "[30 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(correlationMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "We would like to demonstrate the imbalance of the dataset. A few fraudulent cases completely dominated by the majority of non-fraudulent cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count each class\n",
    "count_classes = pd.value_counts(data['Class'])\n",
    "ax = sns.barplot(x=count_classes.index, y=tuple(count_classes / len(data)))\n",
    "ax.set_title('Frequency Percentage by Class')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split the data into a training and a test set, select a cost function and prepare for k-fold cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataX, \n",
    "                                                   dataY, test_size=0.33,\n",
    "                                                   random_state=2018, stratify=dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190820"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93987"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: we need to preserve the ration of fraudulent cases in both splits (around 0.17%). Here, setting the `stratify` param to observe the labels (dataY) will help.\n",
    "\n",
    "The `stratify` parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter `stratify`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017293784718582959"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum() / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017236426314277506"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm will learn by minimizing the loss function. The current dataset is a classification task with two classes. Thus, we can use __binary classification_log_loss__:\n",
    "\n",
    "$$\n",
    "logloss = -\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{M}y_{i,j}log(p_{i,j})\n",
    "$$\n",
    "\n",
    "where $N$ is the number of observations; $M$ is the number of class labels (2 in our case); $log$ is the natural algorithm; $y_{i, j}$ is 1 if observation $i$ is in class $j$  and 0 otherwise; $p_{i, j}$ is the predicted probability that observation $i$ is in class $j$.\n",
    "\n",
    "The algoritm will generate the class probabilities for observations. The closer the probabilities are to true labels, the lower will be the value of the loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create k-Fold cross-validation sets\n",
    "\n",
    "To improve the performance of the algorithm on never-before-seen samples, the training set will be split further into a training and a validation set. The data is split into 5 parts. The training is done on 4 fifth and validated on the 5th part. This will be repeated 5 times, so we will get 5 estimates of the generalization error. The predictions generated fot the validation part will be stored as well as the training and the validation scores for each of the 5 runs. At the end of all runs, we will have validation predictions for all observations in the dataset. This will be the all-in estimate of the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression\n",
    "\n",
    "Logistic regression is the most basic classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up hyperparams\n",
    "\n",
    "penalty = 'l2'\n",
    "C = 1.0\n",
    "class_weight = 'balanced'\n",
    "solver = 'liblinear'\n",
    "n_jobs = 1\n",
    "random_state = 2018\n",
    "\n",
    "logReg = LogisticRegression(penalty=penalty,C=C,\n",
    "                            class_weight=class_weight, random_state=random_state,\n",
    "                           solver=solver, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the penalty is set to $L2$ instead of $L1$. __L2__ is less sensitive to outliers and will assign non-zero weights to all features. This will bring a more stable solution. __L1__, on the other hand, will assign high weights to the most important features and near-zero weight to all the rest, effectibely doing feature selection. However, since the weights vary so much from feature to feature, __L1__ will produce a solution that is not as stable to changes in data points.\n",
    "More details on the choice between the two norms here: http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/\n",
    "\n",
    "__C__ is the strength of the regulariztion. The smaller the number, the stronger is the regularization.\n",
    "\n",
    "__class_weight__ is set to 'balanced' because the dataset is very imbalanced. This tells the algorithm to focus on learning from positively labeled transactions (i.e., the fraudulent ones)\n",
    "\n",
    "\n",
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss:  0.10082094358296365\n",
      "CV Log Loss:  0.10493730171008644\n",
      "Training Log Loss:  0.12098961227815899\n",
      "CV Log Loss:  0.11634808818053684\n",
      "Training Log Loss:  0.1075742826994052\n",
      "CV Log Loss:  0.10845974486799946\n",
      "Training Log Loss:  0.10227736847187828\n",
      "CV Log Loss:  0.10321396356585365\n",
      "Training Log Loss:  0.11502948538215066\n",
      "CV Log Loss:  0.11636069860151103\n",
      "Logistic Regression Log Loss:  0.10986395938519748\n"
     ]
    }
   ],
   "source": [
    "training_scores = []\n",
    "cv_scores = []\n",
    "predictionsBasedOnKFolds = pd.DataFrame(data=[],\n",
    "                                       index=y_train.index, columns=[0,1])\n",
    "\n",
    "model = logReg\n",
    "\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), \n",
    "                                         y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train.iloc[train_index,:], \\\n",
    "        X_train.iloc[cv_index, :]\n",
    "    \n",
    "    y_train_fold, y_cv_fold = y_train.iloc[train_index], \\\n",
    "        y_train.iloc[cv_index]\n",
    "    \n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    loglossTraining = log_loss(y_train_fold, model.predict_proba(X_train_fold)[:, 1])\n",
    "    training_scores.append(loglossTraining)\n",
    "    \n",
    "    predictionsBasedOnKFolds.loc[X_cv_fold.index, :] = \\\n",
    "        model.predict_proba(X_cv_fold)\n",
    "    \n",
    "    loglossCV = log_loss(y_cv_fold, predictionsBasedOnKFolds.loc[X_cv_fold.index, 1])\n",
    "    cv_scores.append(loglossCV)\n",
    "    \n",
    "    print('Training Log Loss: ', loglossTraining)\n",
    "    print('CV Log Loss: ', loglossCV)\n",
    "    \n",
    "loglossLogisticRegression = log_loss(y_train, predictionsBasedOnKFolds.loc[:, 1])\n",
    "print('Logistic Regression Log Loss: ', loglossLogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the results\n",
    "\n",
    "The cross validation loss is higher than the training; that is expected. The loss values are close. The algorithm does not significantly overfit.\n",
    "\n",
    "We need a more intuitive way to interpret the results. The performace of the model is evaluated on how well it distinguishes between good and fraulutent transactions. That is, the closer are the predicted probability of the class to its true label, the better.\n",
    "\n",
    "We need to know, of the given fraudulent transactions, how many were caught? This metric is __recall__.\n",
    "\n",
    "$$\n",
    "recall  = \\frac{N_{true \\ positive}}{N_{true \\ positive} + N_{false \\ negative}}\n",
    "$$\n",
    "\n",
    "\n",
    "Also, out of transaction predicted as fraudulent, how many were actually fraudulent? This metric is __precision__.\n",
    "\n",
    "$$\n",
    "precision  = \\frac{N_{true \\ positive}}{N_{true \\ positive} + N_{false \\ positive}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.concat([y_train, predictionsBasedOnKFolds.loc[:, 1]], axis=1)\n",
    "preds.columns = ['trueLabel', 'prediction']\n",
    "predictionsBasedOnKFoldsLogisticRegression = preds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = average_precision_score(preds['trueLabel'], preds['prediction'])\n",
    "precision, recall, thressholds = precision_recall_curve(preds['trueLabel'], preds['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Precision-Recall curve: Average Precision = 0.73')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "Our dataset is very imbalanced. Tha is, even if we classify all transactions as non-fraudulent, 284315 true negatives, 492 false negatives, 9 true positive, and 0 true false positives. This is not really intuitive and does not reveal the true performance of the algorithm on the highly imbalanced dataset.\n",
    "\n",
    "We need a better way to evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
