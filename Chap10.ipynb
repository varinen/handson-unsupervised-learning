{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chap10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varinen/handson-unsupervised-learning/blob/master/Chap10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N8wD2Eps0uV",
        "colab_type": "text"
      },
      "source": [
        "# Recommender System Using Restricted Boltzmann Machines\n",
        "\n",
        "We are goind to work with *generative model* that learn the probability distribution of the data. The use this knowledge to make inferences on never-before-seen data that is they produce new data that is very close to the real data.\n",
        "\n",
        "The simplest generative model is the **restricted Boltzmann machine**.\n",
        "\n",
        "## Boltzmann Machines\n",
        "\n",
        "Boltzmann Machines were invented in 1985 by Geoffrey Hinton and Terry Sejnowski. **Unrestricted Boltzmann machines** constist of one input layer and one or several hidden layers. During training, neurons in the layers make stochastic desicions when to fire or not based on input data fed to the machine and a cost function that this machine ries to minimize. As the result of this training, a Boltzmann machine learns interesting features abotu the data that help it to model the complex relationships and patterns in the original dataset.\n",
        "\n",
        "However, neurons in such machines are connected not only to neurons in other layers but also to other neurons within the same layer. This makes the training of unrestricted Boltzmann machines very inefficient.\n",
        "\n",
        "### Restricted Boltzmann Machines\n",
        "\n",
        "A simpler version of Boltzmann machines was proposed by Hinton in 2000. It consist only of one input and one hidden layers. It is also **restricted** so that neurons can only connect to neurons on other layers but not within the same one.\n",
        "\n",
        "It was demostrated that stacking of several restricted Boltzmann machines (the output on the hidden layer of one machine is fed into the input layer of the next one) can help learning more nuanced hidden structures in data.\n",
        "\n",
        "Boltzmann machines use *stochastic* approach to learning while autoencoder use *deterministic* approach.\n",
        "\n",
        "\n",
        "For this project we are going to build a recommender system using restricted Boltzmann machines. The recommendations are based on the MovieLens dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZJALNv5m5ga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c27a6b5-f66e-403f-956b-4388adfe3a16"
      },
      "source": [
        "'''Main'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, time, re\n",
        "import pickle, gzip, datetime\n",
        "from datetime import datetime\n",
        "\n",
        "'''Data Viz'''\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "import matplotlib as mpl\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "'''Data Prep and Model Evaluation'''\n",
        "from sklearn import preprocessing as pp\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error\n",
        "\n",
        "'''Algos'''\n",
        "import lightgbm as lgb\n",
        "\n",
        "'''TensorFlow and Keras'''\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from keras.layers import BatchNormalization, Input, Lambda\n",
        "from keras.layers import Embedding, Flatten, dot\n",
        "from keras import regularizers\n",
        "from keras.losses import mse, binary_crossentropy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJPE2SH2nG8v",
        "colab_type": "text"
      },
      "source": [
        "Next, we are going to load the dataset. The dataset is located on Google drive and this will require some additional code to get access to the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_PrhZIhnVNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYew5jccnaWy",
        "colab_type": "code",
        "outputId": "e8af82c0-0a4e-426b-9514-8af8cbc878cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "shareable_link = 'https://drive.google.com/open?id=1trRaJZ639WysCW8mLpmFS1f55o3YYsNq'\n",
        "fluff, id = shareable_link.split('=')\n",
        "print(id)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1trRaJZ639WysCW8mLpmFS1f55o3YYsNq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC9o4vpin41A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Filename.csv')  \n",
        "data = pd.read_csv('Filename.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB-rNigRn6G7",
        "colab_type": "code",
        "outputId": "6720c871-cf64-4a3a-87d6-51d9fadb3ab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112486027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1        2     3.5  1112486027\n",
              "1       1       29     3.5  1112484676\n",
              "2       1       32     3.5  1112484819\n",
              "3       1       47     3.5  1112484727\n",
              "4       1       50     3.5  1112484580"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYHYJK6boNEp",
        "colab_type": "text"
      },
      "source": [
        "The dataset entries have four columns: `user_id`, `movie_id`, `rating`. The last column, `timestamp`, indicates the time the rating was given. There are over 20 million ratings in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs5Nh1HJoJ8n",
        "colab_type": "code",
        "outputId": "6d2bb2e1-d092-474f-b8cb-814fc1ed1601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(data.shape)\n",
        "'''\n",
        "MovieLens 20M Dataset\n",
        "20,000,263 ratings\n",
        "27,278 movies\n",
        "138,493 users\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000263, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nMovieLens 20M Dataset\\n20,000,263 ratings\\n27,278 movies\\n138,493 users\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsbW8WRLpK2w",
        "colab_type": "text"
      },
      "source": [
        "Before we can proceed, we need to convert the dataset columns into appropriate data types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NqovW43ofak",
        "colab_type": "code",
        "outputId": "e574190e-75a8-47f7-b0aa-670cf973748a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "ratingDF = data\n",
        "# Convert fields into appropriate data types\n",
        "ratingDF.userId = ratingDF.userId.astype(str).astype(int)\n",
        "ratingDF.movieId = ratingDF.movieId.astype(str).astype(int)\n",
        "ratingDF.rating = ratingDF.rating.astype(str).astype(float)\n",
        "ratingDF.timestamp = ratingDF.timestamp.apply(lambda x: \\\n",
        "                    datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "# Preview data\n",
        "ratingDF.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:53:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:31:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:33:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:32:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:29:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating            timestamp\n",
              "0       1        2     3.5  2005-04-02 23:53:47\n",
              "1       1       29     3.5  2005-04-02 23:31:16\n",
              "2       1       32     3.5  2005-04-02 23:33:39\n",
              "3       1       47     3.5  2005-04-02 23:32:07\n",
              "4       1       50     3.5  2005-04-02 23:29:40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33mD9VEYraCs",
        "colab_type": "text"
      },
      "source": [
        "Let's save the transformed data into a picke file for faster load in the future. I will mount my Google Drive and save the file there. For more details see https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqGnfDDGpc1z",
        "colab_type": "code",
        "outputId": "b3043985-e3c3-4d91-82b4-b9833f052687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyrqkz4rqB8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_path = 'gdrive/My Drive/Colab Notebooks/movielens_data/'\n",
        "pickle_file = 'ratingPickle'\n",
        "#ratingDF.to_pickle(current_path + pickle_file)\n",
        "ratingDF = pd.read_pickle(current_path + pickle_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO976APCq0Qe",
        "colab_type": "code",
        "outputId": "02e99234-66c8-4188-c43e-de707327e1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ratingDF.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:53:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:31:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:33:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:32:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:29:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating            timestamp\n",
              "0       1        2     3.5  2005-04-02 23:53:47\n",
              "1       1       29     3.5  2005-04-02 23:31:16\n",
              "2       1       32     3.5  2005-04-02 23:33:39\n",
              "3       1       47     3.5  2005-04-02 23:32:07\n",
              "4       1       50     3.5  2005-04-02 23:29:40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQlwNo4bw5pk",
        "colab_type": "text"
      },
      "source": [
        "Let's find out the number of unique users, movies, and calculate the average number of the ratings per user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7s-e9SrrE9s",
        "colab_type": "code",
        "outputId": "c1375a25-e880-4a99-8e8e-29aa20d849d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "n_users = ratingDF.userId.unique().shape[0]\n",
        "print(f'number of users: {n_users}')\n",
        "n_movies = ratingDF.movieId.unique().shape[0]\n",
        "print(f'number of movies: {n_movies}')\n",
        "n_ratings = len(ratingDF)\n",
        "print(f'number of ratings: {n_ratings}')\n",
        "\n",
        "avg_ratings_per_user = n_ratings/n_users\n",
        "print(f'avg number of ratings per user: {avg_ratings_per_user}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of users: 138493\n",
            "number of movies: 26744\n",
            "number of ratings: 20000263\n",
            "avg number of ratings per user: 144.4135299257002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6vC4IkuytX5",
        "colab_type": "text"
      },
      "source": [
        "To reduce the size and complexity of this dataset, we will consider only the 1000 top-rated movies. This will bring down the dataset size from 20 million to about 12.8 million."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoK1rV_OxKIW",
        "colab_type": "code",
        "outputId": "b3344f2c-0106-4410-e368-0277cb8e4d15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Reduce size of dataset by taking top 1000 movies\n",
        "movieIndex = ratingDF.groupby(\"movieId\").count().sort_values(by= \\\n",
        "                \"rating\",ascending=False)[0:1000].index\n",
        "\n",
        "ratingDFX2 = ratingDF[ratingDF.movieId.isin(movieIndex)]\n",
        "ratingDFX2.count()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userId       12840344\n",
              "movieId      12840344\n",
              "rating       12840344\n",
              "timestamp    12840344\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "794l2AuyzYQy",
        "colab_type": "text"
      },
      "source": [
        "To further reduce the dataset, we will sample 1000 random users and filter the dataset only for these users. This will result in a dataset of just 90k entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSihh7UOzHFJ",
        "colab_type": "code",
        "outputId": "56b3aad0-1799-499c-feef-7dd217317f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Reduce size of dataset by sampling 1000 users\n",
        "userIndex = ratingDFX2.groupby(\"userId\").count().sort_values(by= \\\n",
        "    \"rating\",ascending=False).sample(n=1000, random_state=2018).index\n",
        "ratingDFX3 = ratingDFX2[ratingDFX2.userId.isin(userIndex)]\n",
        "ratingDFX3.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userId       90213\n",
              "movieId      90213\n",
              "rating       90213\n",
              "timestamp    90213\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKtl1Lbc0HIH",
        "colab_type": "text"
      },
      "source": [
        "We will also reindex the movie ID and user ID in range of 1 to 1000:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYwjZA8nzuJO",
        "colab_type": "code",
        "outputId": "72cf5f8c-f466-48fc-882d-2bc178f0b495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "movies = ratingDFX3.movieId.unique()\n",
        "moviesDF = pd.DataFrame(data=movies, columns=['originalMovieId'])\n",
        "moviesDF['newMovieId'] = moviesDF.index + 1\n",
        "moviesDF.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>originalMovieId</th>\n",
              "      <th>newMovieId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>216</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>296</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>333</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   originalMovieId  newMovieId\n",
              "0               50           1\n",
              "1              163           2\n",
              "2              216           3\n",
              "3              296           4\n",
              "4              333           5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui8fTnKE0zga",
        "colab_type": "code",
        "outputId": "27cf99f5-4e86-47b5-dfdd-85d1f357eed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "users = ratingDFX3.userId.unique()\n",
        "usersDF = pd.DataFrame(data=users, columns=['originalUserId'])\n",
        "usersDF['newUserId'] = usersDF.index + 1\n",
        "usersDF.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>originalUserId</th>\n",
              "      <th>newUserId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>260</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>311</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>319</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>499</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   originalUserId  newUserId\n",
              "0              49          1\n",
              "1             260          2\n",
              "2             311          3\n",
              "3             319          4\n",
              "4             499          5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvymIcbQ1DJf",
        "colab_type": "code",
        "outputId": "b393ba46-e635-4fa9-af1a-113de814a54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# Generate newly merged DataFrame\n",
        "ratingDFX3 = ratingDFX3.merge(moviesDF,left_on='movieId', \\\n",
        "                              right_on='originalMovieId')\n",
        "ratingDFX3.drop(labels='originalMovieId', axis=1, inplace=True)\n",
        "\n",
        "ratingDFX3 = ratingDFX3.merge(usersDF,left_on='userId', \\\n",
        "                              right_on='originalUserId')\n",
        "ratingDFX3.drop(labels='originalUserId', axis=1, inplace=True)\n",
        "ratingDFX3.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>newMovieId</th>\n",
              "      <th>newUserId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2013-05-03 02:50:26</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>163</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2013-05-03 02:43:37</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49</td>\n",
              "      <td>216</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2013-05-03 02:45:58</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>49</td>\n",
              "      <td>296</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2013-05-03 02:50:13</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49</td>\n",
              "      <td>333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2013-05-03 02:44:38</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating            timestamp  newMovieId  newUserId\n",
              "0      49       50     5.0  2013-05-03 02:50:26           1          1\n",
              "1      49      163     3.5  2013-05-03 02:43:37           2          1\n",
              "2      49      216     3.0  2013-05-03 02:45:58           3          1\n",
              "3      49      296     5.0  2013-05-03 02:50:13           4          1\n",
              "4      49      333     3.0  2013-05-03 02:44:38           5          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_B6VQK02Ufn",
        "colab_type": "text"
      },
      "source": [
        "Now, let's get the number of movies, users, ratings, and the average rating number per user for the new dataset. First, we save the reduced dataset as a picke file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdzN_LtJ1Ln0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save as pickle\n",
        "pickle_file = 'ratingReducedPickle'\n",
        "ratingDFX3.to_pickle(current_path + pickle_file)\n",
        "ratingDFX3 = pd.read_pickle(current_path + pickle_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDK1h3672owc",
        "colab_type": "code",
        "outputId": "200c50cf-5050-43af-c494-d17e95d92315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Calculate summary statistics on reduced dataset\n",
        "n_users = ratingDFX3.userId.unique().shape[0]\n",
        "n_movies = ratingDFX3.movieId.unique().shape[0]\n",
        "n_ratings = len(ratingDFX3)\n",
        "avg_ratings_per_user = n_ratings/n_users\n",
        "\n",
        "print('Number of unique users: ', n_users)\n",
        "print('Number of unique movies: ', n_movies)\n",
        "print('Number of total ratings: ', n_ratings)\n",
        "print('Average number of ratings per user: ', avg_ratings_per_user)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique users:  1000\n",
            "Number of unique movies:  1000\n",
            "Number of total ratings:  90213\n",
            "Average number of ratings per user:  90.213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU83Amn73I-Y",
        "colab_type": "text"
      },
      "source": [
        "Next, we split the reduced dataset into the training and testing sets. The test set we split further into the test and validation sets so that each of them contains 5% of the reduced ratings dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbIkGJba2s93",
        "colab_type": "code",
        "outputId": "ef8d502f-5424-41ac-b785-3ff4150ac046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Split into validation and test, such that each is 5% of the dataset\n",
        "X_train, X_test = train_test_split(ratingDFX3, test_size=0.10, \\\n",
        "                                   shuffle=True, random_state=2018)\n",
        "\n",
        "X_validation, X_test = train_test_split(X_test, test_size=0.50, \\\n",
        "                                        shuffle=True, random_state=2018)\n",
        "\n",
        "# Confirm size of train, validation, and test datasets\n",
        "print('Size of train set: ', len(X_train))\n",
        "print('Size of validation set: ', len(X_validation))\n",
        "print('Size of test set: ', len(X_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of train set:  81191\n",
            "Size of validation set:  4511\n",
            "Size of test set:  4511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQVVkfEj4EHD",
        "colab_type": "text"
      },
      "source": [
        "## Define the Cost Function: Mean Squared Error\n",
        "\n",
        "We are ready to work with the data. We start with creating a rating matrix of $m \\times n$ where $m$ is the number of users and $n$ is the number of movies. This will be a sparse matrix, since only a few movies are rated by each user. For 1000 by 1000 potential ratings we have only 81k ratings available. This means 92% of ratings are not known."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNE7Wftc3i3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate ratings matrix for train\n",
        "ratings_train = np.zeros((n_users, n_movies))\n",
        "for row in X_train.itertuples():\n",
        "    ratings_train[row[6]-1, row[5]-1] = row[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCUF0YL-5XRd",
        "colab_type": "code",
        "outputId": "ffe7f47d-2862-4872-8e5a-d3bf48070cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Calculate sparsity of the train ratings matrix\n",
        "sparsity = float(len(ratings_train.nonzero()[0]))\n",
        "sparsity /= (ratings_train.shape[0] * ratings_train.shape[1])\n",
        "sparsity *= 100\n",
        "print('Sparsity: {:4.2f}%'.format(sparsity))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity: 8.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVbW0UCx5qxN",
        "colab_type": "text"
      },
      "source": [
        "We also generate similar matrices for the test and validation sets. They will be even sparcer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdKKYBnT5ybp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate ratings matrix for validation\n",
        "ratings_validation = np.zeros((n_users, n_movies))\n",
        "for row in X_validation.itertuples():\n",
        "    ratings_validation[row[6]-1, row[5]-1] = row[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu-OzxZ153VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate ratings matrix for test\n",
        "ratings_test = np.zeros((n_users, n_movies))\n",
        "for row in X_test.itertuples():\n",
        "    ratings_test[row[6]-1, row[5]-1] = row[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGK9pkux55e3",
        "colab_type": "code",
        "outputId": "06dfb999-ad4f-4312-8ca5-10f1d2e6c18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Calculate sparsity of the validation ratings matrix\n",
        "sparsity = float(len(ratings_validation.nonzero()[0]))\n",
        "sparsity /= (ratings_validation.shape[0] * ratings_validation.shape[1])\n",
        "sparsity *= 100\n",
        "print('Sparsity: {:4.2f}%'.format(sparsity))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity: 0.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQN8pjW16Oak",
        "colab_type": "text"
      },
      "source": [
        "Before we build the recommender system, we need to define the cost function. We are going to use *mean squared error*. To calculate MSE, we will need two vectors of size $n \\times 1$, one for the actal ratings and one for the predicted. The number $n$ s the size of the validation set, that is, 4511. We can start by preparing the ratings vector from the validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sPX1dBB58fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actual_validation = ratings_validation[ratings_validation.nonzero()].flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR4Av9aW67o2",
        "colab_type": "code",
        "outputId": "c16da327-b8c4-4464-f05c-c09cb6529795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "actual_validation.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4511,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_s-jO4F7uhW",
        "colab_type": "text"
      },
      "source": [
        "## Baseline Experiments\n",
        "\n",
        "To establish a baseline value for the MSE, let's make a naive prediction of all ratings equal 3.5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mypSaGHs68_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_validation = np.zeros((len(X_validation),1))\n",
        "pred_validation[pred_validation==0] = 3.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDDHtUVO8EyZ",
        "colab_type": "text"
      },
      "source": [
        "The MSE of this prediction is 1.06. This is our baseline cost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioQfpW7Y8Bhj",
        "colab_type": "code",
        "outputId": "7ce983bc-edac-46c6-c257-579f0f0f2566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "naive_prediction = mean_squared_error(pred_validation, actual_validation)\n",
        "print('Mean squared error using naive prediction:', naive_prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error using naive prediction: 1.055420084238528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHpBfBG-8Ynh",
        "colab_type": "text"
      },
      "source": [
        "Our next prediction is that the user's rating to an unrated movie equals his average rating. Let's see if it can improve the baseline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1QPJOh8Kvz",
        "colab_type": "code",
        "outputId": "006aa3b8-6ff0-4a90-94f5-aa5c3de0e64e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Experiment two - Predict a user's rating based on user's average rating \n",
        "# for all other movies\n",
        "ratings_validation_prediction = np.zeros((n_users, n_movies))\n",
        "i = 0\n",
        "for row in ratings_train:\n",
        "    ratings_validation_prediction[i][ratings_validation_prediction[i]==0] \\\n",
        "        = np.mean(row[row>0])\n",
        "    i += 1\n",
        "\n",
        "pred_validation = ratings_validation_prediction \\\n",
        "    [ratings_validation.nonzero()].flatten()\n",
        "user_average = mean_squared_error(pred_validation, actual_validation)\n",
        "print('Mean squared error using user average:', user_average)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error using user average: 0.9090717929472647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn-6kgZl85ad",
        "colab_type": "text"
      },
      "source": [
        "We see some improvement there. The next experimental prediction is that the user's rating to an unrated movie is equal to the average rating other user ave to this movie:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX8L3TKZ80Hg",
        "colab_type": "code",
        "outputId": "81bb851e-2bcc-4428-8a70-0416e84c0ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Experiment three - Predict a user's rating for a movie based on the\n",
        "# average rating other users have given that movie\n",
        "ratings_validation_prediction = np.zeros((n_users, n_movies)).T\n",
        "i = 0\n",
        "for row in ratings_train.T:\n",
        "    ratings_validation_prediction[i][ratings_validation_prediction[i]==0] \\\n",
        "        = np.mean(row[row>0])\n",
        "    i += 1\n",
        "\n",
        "ratings_validation_prediction = ratings_validation_prediction.T\n",
        "pred_validation = ratings_validation_prediction \\\n",
        "    [ratings_validation.nonzero()].flatten()\n",
        "movie_average = mean_squared_error(pred_validation, actual_validation)\n",
        "print('Mean squared error using movie average:', movie_average)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error using movie average: 0.9136057106858655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX4E1uRm9xFH",
        "colab_type": "text"
      },
      "source": [
        "The result is similar bt not better when using the user's own ratings. However, this approach is better applicable to users that never rated any movie.\n",
        "\n",
        "## Matrix Factorization\n",
        "\n",
        "Before we continue building a recommender system using restricted Boltzmann machines, we will try a popular method called **matrix factorization**. The idea behind this method is that the users-movies matrix can be represented as a product of two matrices based on so called *latent factors*. One matrix, the user - latent factor matrix, has dimensions $m \\times k$, where $k$ is the chosen number of latent factors. The other matrix, movies-lantent factors, has the dmensionality $k \\times n$.\n",
        "\n",
        "The higher is the number of latent factors, the higher is the matrix capacity. However, the high capacity matrices can overfit the data.\n",
        "\n",
        "Matrix factorisation learns the representations of users and items in a lower-dimensional space and makes predictions based on the learned representation.\n",
        "\n",
        "### One Latent Factor\n",
        "\n",
        "We will start with the simplest scenario: one latent factor. We will use Keras to perform matrix factorization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GAhjXbR9Ngs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Experiment four - Recommender System using Matrix Factorization\n",
        "# 1 Latent Factor\n",
        "\n",
        "n_latent_factors = 1\n",
        "\n",
        "user_input = Input(shape=[1], name='user')\n",
        "user_embedding = Embedding(input_dim=n_users + 1, \\\n",
        "                           output_dim=n_latent_factors, \\\n",
        "                           name='user_embedding')(user_input)\n",
        "user_vec = Flatten(name='flatten_users')(user_embedding)\n",
        "\n",
        "movie_input = Input(shape=[1], name='movie')\n",
        "movie_embedding = Embedding(input_dim=n_movies + 1, \\\n",
        "                            output_dim=n_latent_factors,\n",
        "                            name='movie_embedding')(movie_input)\n",
        "movie_vec = Flatten(name='flatten_movies')(movie_embedding)\n",
        "\n",
        "product = dot([movie_vec, user_vec], axes=1)\n",
        "model = Model(inputs=[user_input, movie_input], outputs=product)\n",
        "model.compile('adam', 'mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm0IZsHugQNz",
        "colab_type": "text"
      },
      "source": [
        "We will train the model by feeding it the user and movies vectors for 100 epochs. We will validate using the validation set. The MSE will be calculated against the actual ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KzE2DHufzP-",
        "colab_type": "code",
        "outputId": "b5687dbc-e530-415c-c5bb-a936432013f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x=[X_train.newUserId, X_train.newMovieId], \\\n",
        "                    y=X_train.rating, epochs=100, \\\n",
        "                    validation_data=([X_validation.newUserId, \\\n",
        "                    X_validation.newMovieId], X_validation.rating), \\\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0626 11:19:08.120711 140602987935616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0626 11:19:08.208771 140602987935616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 81191 samples, validate on 4511 samples\n",
            "Epoch 1/100\n",
            "81191/81191 [==============================] - 4s 48us/step - loss: 13.3784 - val_loss: 11.4233\n",
            "Epoch 2/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 8.7118 - val_loss: 6.2086\n",
            "Epoch 3/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 4.4347 - val_loss: 3.2328\n",
            "Epoch 4/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 2.4776 - val_loss: 2.0073\n",
            "Epoch 5/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 1.6109 - val_loss: 1.4189\n",
            "Epoch 6/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 1.1819 - val_loss: 1.1253\n",
            "Epoch 7/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.9645 - val_loss: 0.9711\n",
            "Epoch 8/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.8532 - val_loss: 0.8910\n",
            "Epoch 9/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7953 - val_loss: 0.8475\n",
            "Epoch 10/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7647 - val_loss: 0.8249\n",
            "Epoch 11/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7482 - val_loss: 0.8132\n",
            "Epoch 12/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7395 - val_loss: 0.8072\n",
            "Epoch 13/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7346 - val_loss: 0.8042\n",
            "Epoch 14/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7318 - val_loss: 0.8015\n",
            "Epoch 15/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7303 - val_loss: 0.8006\n",
            "Epoch 16/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7295 - val_loss: 0.7995\n",
            "Epoch 17/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7287 - val_loss: 0.7988\n",
            "Epoch 18/100\n",
            "81191/81191 [==============================] - 3s 34us/step - loss: 0.7284 - val_loss: 0.7998\n",
            "Epoch 19/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7283 - val_loss: 0.7998\n",
            "Epoch 20/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7280 - val_loss: 0.7995\n",
            "Epoch 21/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7281 - val_loss: 0.7974\n",
            "Epoch 22/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7280 - val_loss: 0.7994\n",
            "Epoch 23/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7280 - val_loss: 0.7992\n",
            "Epoch 24/100\n",
            "81191/81191 [==============================] - 3s 36us/step - loss: 0.7279 - val_loss: 0.7984\n",
            "Epoch 25/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7280 - val_loss: 0.7974\n",
            "Epoch 26/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7279 - val_loss: 0.7978\n",
            "Epoch 27/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7279 - val_loss: 0.7971\n",
            "Epoch 28/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7982\n",
            "Epoch 29/100\n",
            "81191/81191 [==============================] - 3s 34us/step - loss: 0.7279 - val_loss: 0.7979\n",
            "Epoch 30/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7985\n",
            "Epoch 31/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7964\n",
            "Epoch 32/100\n",
            "81191/81191 [==============================] - 3s 34us/step - loss: 0.7279 - val_loss: 0.7974\n",
            "Epoch 33/100\n",
            "81191/81191 [==============================] - 3s 34us/step - loss: 0.7279 - val_loss: 0.7976\n",
            "Epoch 34/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7966\n",
            "Epoch 35/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7978\n",
            "Epoch 36/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7987\n",
            "Epoch 37/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7972\n",
            "Epoch 38/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7276 - val_loss: 0.7991\n",
            "Epoch 39/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7969\n",
            "Epoch 40/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7988\n",
            "Epoch 41/100\n",
            "81191/81191 [==============================] - 3s 34us/step - loss: 0.7278 - val_loss: 0.7981\n",
            "Epoch 42/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7275 - val_loss: 0.7990\n",
            "Epoch 43/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7987\n",
            "Epoch 44/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7276 - val_loss: 0.7987\n",
            "Epoch 45/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7984\n",
            "Epoch 46/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7980\n",
            "Epoch 47/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7981\n",
            "Epoch 48/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7982\n",
            "Epoch 49/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7991\n",
            "Epoch 50/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7981\n",
            "Epoch 51/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7982\n",
            "Epoch 52/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7986\n",
            "Epoch 53/100\n",
            "81191/81191 [==============================] - 3s 38us/step - loss: 0.7277 - val_loss: 0.7990\n",
            "Epoch 54/100\n",
            "81191/81191 [==============================] - 3s 38us/step - loss: 0.7276 - val_loss: 0.7985\n",
            "Epoch 55/100\n",
            "81191/81191 [==============================] - 3s 37us/step - loss: 0.7276 - val_loss: 0.8005\n",
            "Epoch 56/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7276 - val_loss: 0.7980\n",
            "Epoch 57/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7987\n",
            "Epoch 58/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7984\n",
            "Epoch 59/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7974\n",
            "Epoch 60/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7978\n",
            "Epoch 61/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7983\n",
            "Epoch 62/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7276 - val_loss: 0.7986\n",
            "Epoch 63/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7988\n",
            "Epoch 64/100\n",
            "81191/81191 [==============================] - 3s 36us/step - loss: 0.7277 - val_loss: 0.7982\n",
            "Epoch 65/100\n",
            "81191/81191 [==============================] - 3s 34us/step - loss: 0.7276 - val_loss: 0.7980\n",
            "Epoch 66/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7985\n",
            "Epoch 67/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7975\n",
            "Epoch 68/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7990\n",
            "Epoch 69/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7994\n",
            "Epoch 70/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7276 - val_loss: 0.7990\n",
            "Epoch 71/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7988\n",
            "Epoch 72/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7980\n",
            "Epoch 73/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7976\n",
            "Epoch 74/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7276 - val_loss: 0.7974\n",
            "Epoch 75/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7977\n",
            "Epoch 76/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7972\n",
            "Epoch 77/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7972\n",
            "Epoch 78/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7977\n",
            "Epoch 79/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7987\n",
            "Epoch 80/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7985\n",
            "Epoch 81/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7981\n",
            "Epoch 82/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7979\n",
            "Epoch 83/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7276 - val_loss: 0.7987\n",
            "Epoch 84/100\n",
            "81191/81191 [==============================] - 3s 34us/step - loss: 0.7279 - val_loss: 0.7985\n",
            "Epoch 85/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.8004\n",
            "Epoch 86/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7987\n",
            "Epoch 87/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7967\n",
            "Epoch 88/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7987\n",
            "Epoch 89/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7279 - val_loss: 0.7994\n",
            "Epoch 90/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7978\n",
            "Epoch 91/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7989\n",
            "Epoch 92/100\n",
            "81191/81191 [==============================] - 3s 36us/step - loss: 0.7279 - val_loss: 0.7983\n",
            "Epoch 93/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7276 - val_loss: 0.7986\n",
            "Epoch 94/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7983\n",
            "Epoch 95/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7279 - val_loss: 0.7987\n",
            "Epoch 96/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7985\n",
            "Epoch 97/100\n",
            "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7982\n",
            "Epoch 98/100\n",
            "81191/81191 [==============================] - 3s 36us/step - loss: 0.7278 - val_loss: 0.7973\n",
            "Epoch 99/100\n",
            "81191/81191 [==============================] - 3s 38us/step - loss: 0.7277 - val_loss: 0.7976\n",
            "Epoch 100/100\n",
            "81191/81191 [==============================] - 5s 64us/step - loss: 0.7278 - val_loss: 0.7971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-wAzhj5iO0s",
        "colab_type": "text"
      },
      "source": [
        "Let's plot the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAHH_qObgs3J",
        "colab_type": "code",
        "outputId": "0962c587-0c2c-47b1-a866-478be2c0e926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "pd.Series(history.history['val_loss'][10:]).plot(logy=False)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation Error\")\n",
        "print('Minimum MSE: ', min(history.history['val_loss']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum MSE:  0.796398781588484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naQgTjCRpCBOMJGmIX+ELloUysXaXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx-1ijiGiwVn",
        "colab_type": "text"
      },
      "source": [
        "The minimum MSE is 0.796, which is better than our baseline values. Let's see if this can be improved with more latent factors.\n",
        "\n",
        "### Three Latent Factors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VwLEpNRiSjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Experiment five - Recommender System using Matrix Factorization\n",
        "# 3 Latent Factors\n",
        "n_latent_factors = 3\n",
        "\n",
        "user_input = Input(shape=[1], name='user')\n",
        "user_embedding = Embedding(input_dim=n_users + 1, \\\n",
        "                           output_dim=n_latent_factors, \\\n",
        "                           embeddings_regularizer=regularizers.l1(10e-7), \\\n",
        "                           name='user_embedding')(user_input)\n",
        "user_vec = Flatten(name='flatten_users')(user_embedding)\n",
        "\n",
        "movie_input = Input(shape=[1], name='movie')\n",
        "movie_embedding = Embedding(input_dim=n_movies + 1, \\\n",
        "                            output_dim=n_latent_factors, \\\n",
        "                            embeddings_regularizer=regularizers.l1(10e-7), \\\n",
        "                            name='movie_embedding')(movie_input)\n",
        "movie_vec = Flatten(name='flatten_movies')(movie_embedding)\n",
        "\n",
        "product = dot([movie_vec, user_vec], axes=1)\n",
        "model = Model(inputs=[user_input, movie_input], outputs=product)\n",
        "model.compile('adam', 'mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t8Pye8EjZkS",
        "colab_type": "code",
        "outputId": "864acafa-b455-45d0-9744-fd683c2d9982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x=[X_train.newUserId, X_train.newMovieId], \\\n",
        "                    y=X_train.rating, epochs=100, \\\n",
        "                    validation_data=([X_validation.newUserId, \\\n",
        "                    X_validation.newMovieId], X_validation.rating), \\\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 81191 samples, validate on 4511 samples\n",
            "Epoch 1/100\n",
            "81191/81191 [==============================] - 4s 45us/step - loss: 12.1686 - val_loss: 7.7053\n",
            "Epoch 2/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 4.3921 - val_loss: 2.5150\n",
            "Epoch 3/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 1.7681 - val_loss: 1.3573\n",
            "Epoch 4/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 1.0775 - val_loss: 0.9949\n",
            "Epoch 5/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.8569 - val_loss: 0.8705\n",
            "Epoch 6/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7830 - val_loss: 0.8281\n",
            "Epoch 7/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7577 - val_loss: 0.8156\n",
            "Epoch 8/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7487 - val_loss: 0.8094\n",
            "Epoch 9/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7447 - val_loss: 0.8094\n",
            "Epoch 10/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7432 - val_loss: 0.8088\n",
            "Epoch 11/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7428 - val_loss: 0.8076\n",
            "Epoch 12/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7423 - val_loss: 0.8080\n",
            "Epoch 13/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7416 - val_loss: 0.8070\n",
            "Epoch 14/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7419 - val_loss: 0.8074\n",
            "Epoch 15/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7411 - val_loss: 0.8056\n",
            "Epoch 16/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7409 - val_loss: 0.8058\n",
            "Epoch 17/100\n",
            "81191/81191 [==============================] - 4s 43us/step - loss: 0.7405 - val_loss: 0.8049\n",
            "Epoch 18/100\n",
            "81191/81191 [==============================] - 4s 44us/step - loss: 0.7401 - val_loss: 0.8008\n",
            "Epoch 19/100\n",
            "81191/81191 [==============================] - 4s 43us/step - loss: 0.7395 - val_loss: 0.8028\n",
            "Epoch 20/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7384 - val_loss: 0.8035\n",
            "Epoch 21/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7373 - val_loss: 0.8028\n",
            "Epoch 22/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7363 - val_loss: 0.8032\n",
            "Epoch 23/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7344 - val_loss: 0.7993\n",
            "Epoch 24/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7324 - val_loss: 0.7979\n",
            "Epoch 25/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7301 - val_loss: 0.7976\n",
            "Epoch 26/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7272 - val_loss: 0.7973\n",
            "Epoch 27/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7237 - val_loss: 0.7920\n",
            "Epoch 28/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7203 - val_loss: 0.7892\n",
            "Epoch 29/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.7160 - val_loss: 0.7896\n",
            "Epoch 30/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7119 - val_loss: 0.7870\n",
            "Epoch 31/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7070 - val_loss: 0.7837\n",
            "Epoch 32/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7022 - val_loss: 0.7816\n",
            "Epoch 33/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6980 - val_loss: 0.7784\n",
            "Epoch 34/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6939 - val_loss: 0.7767\n",
            "Epoch 35/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6897 - val_loss: 0.7752\n",
            "Epoch 36/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6858 - val_loss: 0.7735\n",
            "Epoch 37/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6822 - val_loss: 0.7735\n",
            "Epoch 38/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6788 - val_loss: 0.7726\n",
            "Epoch 39/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6754 - val_loss: 0.7706\n",
            "Epoch 40/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6725 - val_loss: 0.7688\n",
            "Epoch 41/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6691 - val_loss: 0.7658\n",
            "Epoch 42/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6665 - val_loss: 0.7689\n",
            "Epoch 43/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6633 - val_loss: 0.7642\n",
            "Epoch 44/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6606 - val_loss: 0.7620\n",
            "Epoch 45/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6576 - val_loss: 0.7635\n",
            "Epoch 46/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6551 - val_loss: 0.7651\n",
            "Epoch 47/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6527 - val_loss: 0.7640\n",
            "Epoch 48/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6499 - val_loss: 0.7617\n",
            "Epoch 49/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6479 - val_loss: 0.7616\n",
            "Epoch 50/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6458 - val_loss: 0.7604\n",
            "Epoch 51/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6438 - val_loss: 0.7622\n",
            "Epoch 52/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6421 - val_loss: 0.7626\n",
            "Epoch 53/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6402 - val_loss: 0.7578\n",
            "Epoch 54/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6386 - val_loss: 0.7592\n",
            "Epoch 55/100\n",
            "81191/81191 [==============================] - 4s 43us/step - loss: 0.6373 - val_loss: 0.7600\n",
            "Epoch 56/100\n",
            "81191/81191 [==============================] - 3s 43us/step - loss: 0.6359 - val_loss: 0.7600\n",
            "Epoch 57/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6345 - val_loss: 0.7610\n",
            "Epoch 58/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6334 - val_loss: 0.7586\n",
            "Epoch 59/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6325 - val_loss: 0.7598\n",
            "Epoch 60/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6312 - val_loss: 0.7590\n",
            "Epoch 61/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6300 - val_loss: 0.7608\n",
            "Epoch 62/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6293 - val_loss: 0.7587\n",
            "Epoch 63/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6285 - val_loss: 0.7591\n",
            "Epoch 64/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6278 - val_loss: 0.7582\n",
            "Epoch 65/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6270 - val_loss: 0.7627\n",
            "Epoch 66/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6265 - val_loss: 0.7604\n",
            "Epoch 67/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6256 - val_loss: 0.7626\n",
            "Epoch 68/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6249 - val_loss: 0.7599\n",
            "Epoch 69/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6243 - val_loss: 0.7589\n",
            "Epoch 70/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6239 - val_loss: 0.7606\n",
            "Epoch 71/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6233 - val_loss: 0.7606\n",
            "Epoch 72/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6229 - val_loss: 0.7600\n",
            "Epoch 73/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6223 - val_loss: 0.7618\n",
            "Epoch 74/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6218 - val_loss: 0.7617\n",
            "Epoch 75/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6214 - val_loss: 0.7639\n",
            "Epoch 76/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6210 - val_loss: 0.7622\n",
            "Epoch 77/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6208 - val_loss: 0.7614\n",
            "Epoch 78/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6202 - val_loss: 0.7644\n",
            "Epoch 79/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6201 - val_loss: 0.7634\n",
            "Epoch 80/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6198 - val_loss: 0.7630\n",
            "Epoch 81/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6194 - val_loss: 0.7631\n",
            "Epoch 82/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6191 - val_loss: 0.7636\n",
            "Epoch 83/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6189 - val_loss: 0.7646\n",
            "Epoch 84/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6186 - val_loss: 0.7645\n",
            "Epoch 85/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6182 - val_loss: 0.7631\n",
            "Epoch 86/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6179 - val_loss: 0.7648\n",
            "Epoch 87/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6179 - val_loss: 0.7670\n",
            "Epoch 88/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6175 - val_loss: 0.7667\n",
            "Epoch 89/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6174 - val_loss: 0.7649\n",
            "Epoch 90/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6172 - val_loss: 0.7655\n",
            "Epoch 91/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6171 - val_loss: 0.7653\n",
            "Epoch 92/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6167 - val_loss: 0.7640\n",
            "Epoch 93/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6165 - val_loss: 0.7644\n",
            "Epoch 94/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6166 - val_loss: 0.7649\n",
            "Epoch 95/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6162 - val_loss: 0.7671\n",
            "Epoch 96/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6163 - val_loss: 0.7661\n",
            "Epoch 97/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6158 - val_loss: 0.7646\n",
            "Epoch 98/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6157 - val_loss: 0.7640\n",
            "Epoch 99/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6158 - val_loss: 0.7646\n",
            "Epoch 100/100\n",
            "81191/81191 [==============================] - 3s 40us/step - loss: 0.6154 - val_loss: 0.7674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov5gzpQWjcEB",
        "colab_type": "code",
        "outputId": "09cc2282-6c7a-4eb0-8fb7-f874b971c497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "pd.Series(history.history['val_loss'][10:]).plot(logy=False)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation Error\")\n",
        "print('Minimum MSE: ', min(history.history['val_loss']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum MSE:  0.7578070477539778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoQxZGWuk0zy",
        "colab_type": "text"
      },
      "source": [
        "The minimum MSE here is 0.758, so far the best.\n",
        "\n",
        "### Five Latent Factors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuKOgIzrkyxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Experiment six - Recommender System using Matrix Factorization\n",
        "# 5 Latent Factors\n",
        "n_latent_factors = 5\n",
        "\n",
        "user_input = Input(shape=[1], name='user')\n",
        "user_embedding = Embedding(input_dim=n_users + 1, \\\n",
        "                           output_dim=n_latent_factors, \\\n",
        "                           embeddings_regularizer=regularizers.l1(10e-7), \\\n",
        "                           name='user_embedding')(user_input)\n",
        "user_vec = Flatten(name='flatten_users')(user_embedding)\n",
        "\n",
        "movie_input = Input(shape=[1], name='movie')\n",
        "movie_embedding = Embedding(input_dim=n_movies + 1, \\\n",
        "                            output_dim=n_latent_factors, \\\n",
        "                            embeddings_regularizer=regularizers.l1(10e-7), \\\n",
        "                            name='movie_embedding')(movie_input)\n",
        "movie_vec = Flatten(name='flatten_movies')(movie_embedding)\n",
        "\n",
        "product = dot([movie_vec, user_vec], axes=1)\n",
        "model = Model(inputs=[user_input, movie_input], outputs=product)\n",
        "model.compile('adam', 'mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBE13qRFlPTx",
        "colab_type": "code",
        "outputId": "6b0c5613-e0a4-4dd6-d53e-1fdbc2e055fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x=[X_train.newUserId, X_train.newMovieId], \\\n",
        "                    y=X_train.rating, epochs=100, \\\n",
        "                    validation_data=([X_validation.newUserId, \\\n",
        "                    X_validation.newMovieId], X_validation.rating), \\\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 81191 samples, validate on 4511 samples\n",
            "Epoch 1/100\n",
            "81191/81191 [==============================] - 4s 47us/step - loss: 10.9135 - val_loss: 5.2047\n",
            "Epoch 2/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 2.8242 - val_loss: 1.6737\n",
            "Epoch 3/100\n",
            "81191/81191 [==============================] - 4s 44us/step - loss: 1.2164 - val_loss: 1.0257\n",
            "Epoch 4/100\n",
            "81191/81191 [==============================] - 4s 44us/step - loss: 0.8691 - val_loss: 0.8723\n",
            "Epoch 5/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7823 - val_loss: 0.8274\n",
            "Epoch 6/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7591 - val_loss: 0.8174\n",
            "Epoch 7/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7526 - val_loss: 0.8134\n",
            "Epoch 8/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.7500 - val_loss: 0.8116\n",
            "Epoch 9/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7499 - val_loss: 0.8134\n",
            "Epoch 10/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7486 - val_loss: 0.8114\n",
            "Epoch 11/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7482 - val_loss: 0.8096\n",
            "Epoch 12/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7475 - val_loss: 0.8116\n",
            "Epoch 13/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7468 - val_loss: 0.8092\n",
            "Epoch 14/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7458 - val_loss: 0.8099\n",
            "Epoch 15/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7446 - val_loss: 0.8070\n",
            "Epoch 16/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7433 - val_loss: 0.8040\n",
            "Epoch 17/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7413 - val_loss: 0.8021\n",
            "Epoch 18/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7383 - val_loss: 0.8016\n",
            "Epoch 19/100\n",
            "81191/81191 [==============================] - 3s 43us/step - loss: 0.7354 - val_loss: 0.8017\n",
            "Epoch 20/100\n",
            "81191/81191 [==============================] - 3s 43us/step - loss: 0.7313 - val_loss: 0.7975\n",
            "Epoch 21/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7268 - val_loss: 0.7935\n",
            "Epoch 22/100\n",
            "81191/81191 [==============================] - 3s 43us/step - loss: 0.7211 - val_loss: 0.7918\n",
            "Epoch 23/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7148 - val_loss: 0.7892\n",
            "Epoch 24/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7086 - val_loss: 0.7837\n",
            "Epoch 25/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.7021 - val_loss: 0.7800\n",
            "Epoch 26/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6948 - val_loss: 0.7771\n",
            "Epoch 27/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6885 - val_loss: 0.7721\n",
            "Epoch 28/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6823 - val_loss: 0.7703\n",
            "Epoch 29/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6760 - val_loss: 0.7659\n",
            "Epoch 30/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6700 - val_loss: 0.7670\n",
            "Epoch 31/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6642 - val_loss: 0.7629\n",
            "Epoch 32/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6586 - val_loss: 0.7647\n",
            "Epoch 33/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6532 - val_loss: 0.7622\n",
            "Epoch 34/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6479 - val_loss: 0.7596\n",
            "Epoch 35/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6428 - val_loss: 0.7599\n",
            "Epoch 36/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6378 - val_loss: 0.7576\n",
            "Epoch 37/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6332 - val_loss: 0.7624\n",
            "Epoch 38/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6284 - val_loss: 0.7634\n",
            "Epoch 39/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6245 - val_loss: 0.7636\n",
            "Epoch 40/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6203 - val_loss: 0.7591\n",
            "Epoch 41/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6167 - val_loss: 0.7645\n",
            "Epoch 42/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6130 - val_loss: 0.7627\n",
            "Epoch 43/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6096 - val_loss: 0.7645\n",
            "Epoch 44/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.6067 - val_loss: 0.7636\n",
            "Epoch 45/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6039 - val_loss: 0.7617\n",
            "Epoch 46/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.6012 - val_loss: 0.7696\n",
            "Epoch 47/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5985 - val_loss: 0.7680\n",
            "Epoch 48/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5963 - val_loss: 0.7658\n",
            "Epoch 49/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5940 - val_loss: 0.7687\n",
            "Epoch 50/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5919 - val_loss: 0.7728\n",
            "Epoch 51/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5899 - val_loss: 0.7736\n",
            "Epoch 52/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5879 - val_loss: 0.7732\n",
            "Epoch 53/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5861 - val_loss: 0.7742\n",
            "Epoch 54/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5844 - val_loss: 0.7748\n",
            "Epoch 55/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5829 - val_loss: 0.7725\n",
            "Epoch 56/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5817 - val_loss: 0.7722\n",
            "Epoch 57/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5802 - val_loss: 0.7738\n",
            "Epoch 58/100\n",
            "81191/81191 [==============================] - 4s 44us/step - loss: 0.5789 - val_loss: 0.7766\n",
            "Epoch 59/100\n",
            "81191/81191 [==============================] - 4s 45us/step - loss: 0.5777 - val_loss: 0.7773\n",
            "Epoch 60/100\n",
            "81191/81191 [==============================] - 4s 44us/step - loss: 0.5764 - val_loss: 0.7783\n",
            "Epoch 61/100\n",
            "81191/81191 [==============================] - 3s 43us/step - loss: 0.5751 - val_loss: 0.7794\n",
            "Epoch 62/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5742 - val_loss: 0.7757\n",
            "Epoch 63/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5733 - val_loss: 0.7756\n",
            "Epoch 64/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.5725 - val_loss: 0.7823\n",
            "Epoch 65/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.5714 - val_loss: 0.7827\n",
            "Epoch 66/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5705 - val_loss: 0.7811\n",
            "Epoch 67/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5698 - val_loss: 0.7812\n",
            "Epoch 68/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5686 - val_loss: 0.7861\n",
            "Epoch 69/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5679 - val_loss: 0.7869\n",
            "Epoch 70/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5673 - val_loss: 0.7828\n",
            "Epoch 71/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5666 - val_loss: 0.7846\n",
            "Epoch 72/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5655 - val_loss: 0.7853\n",
            "Epoch 73/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5652 - val_loss: 0.7870\n",
            "Epoch 74/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5646 - val_loss: 0.7853\n",
            "Epoch 75/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5639 - val_loss: 0.7841\n",
            "Epoch 76/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5635 - val_loss: 0.7868\n",
            "Epoch 77/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5627 - val_loss: 0.7883\n",
            "Epoch 78/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.5624 - val_loss: 0.7917\n",
            "Epoch 79/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5618 - val_loss: 0.7916\n",
            "Epoch 80/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5616 - val_loss: 0.7899\n",
            "Epoch 81/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5606 - val_loss: 0.7922\n",
            "Epoch 82/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5602 - val_loss: 0.7897\n",
            "Epoch 83/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5599 - val_loss: 0.7913\n",
            "Epoch 84/100\n",
            "81191/81191 [==============================] - 4s 43us/step - loss: 0.5593 - val_loss: 0.7916\n",
            "Epoch 85/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5592 - val_loss: 0.7926\n",
            "Epoch 86/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5586 - val_loss: 0.7921\n",
            "Epoch 87/100\n",
            "81191/81191 [==============================] - 3s 43us/step - loss: 0.5583 - val_loss: 0.7958\n",
            "Epoch 88/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5578 - val_loss: 0.7908\n",
            "Epoch 89/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5577 - val_loss: 0.7931\n",
            "Epoch 90/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.5572 - val_loss: 0.7956\n",
            "Epoch 91/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5567 - val_loss: 0.7960\n",
            "Epoch 92/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5562 - val_loss: 0.7964\n",
            "Epoch 93/100\n",
            "81191/81191 [==============================] - 4s 45us/step - loss: 0.5562 - val_loss: 0.7962\n",
            "Epoch 94/100\n",
            "81191/81191 [==============================] - 4s 45us/step - loss: 0.5558 - val_loss: 0.7970\n",
            "Epoch 95/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5556 - val_loss: 0.7973\n",
            "Epoch 96/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5552 - val_loss: 0.7970\n",
            "Epoch 97/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5548 - val_loss: 0.7961\n",
            "Epoch 98/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.5544 - val_loss: 0.7978\n",
            "Epoch 99/100\n",
            "81191/81191 [==============================] - 3s 41us/step - loss: 0.5543 - val_loss: 0.8017\n",
            "Epoch 100/100\n",
            "81191/81191 [==============================] - 3s 42us/step - loss: 0.5539 - val_loss: 0.7999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEfEQyQMlRUY",
        "colab_type": "code",
        "outputId": "3688d742-86d3-4f82-813f-9659cf01e807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "pd.Series(history.history['val_loss'][10:]).plot(logy=False)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation Error\")\n",
        "print('Minimum MSE: ', min(history.history['val_loss']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum MSE:  0.7576441799714332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x/sHZ9r2K5H7wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9RiJzJLm0Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyP6D7cem1RE",
        "colab_type": "text"
      },
      "source": [
        "This experiment shown overfitting from epoch 25 onwards. The MSE reachesist minimum of 0.758 and then fails to improve. A better result was achieved with 3 latent factors.\n",
        "\n",
        "\n",
        "## Colaborative Filtering Using RBMs\n",
        "\n",
        "Let's recall the architecture of RMBs. They have two layers: an input and hidden. Neurons are connected to neurons in other layers but not to neurons in the same layer.\n",
        "\n",
        "One difference RMBs have compared to autoencoders is that the communication between layers in RBMs happens in both directions whereas in autoencoders only in the forward direction.\n",
        "\n",
        "In RMBs the input data gets passed from the visible layer to the hidden one and back several times. This develops a *generative model* that produces an output similar to the input data.\n",
        "\n",
        "In our case, an RMB will try to generate a rating prediction on a movie a user have never seen based on how similar the movie is to those the user rated before and how similar the user is to users that rated the movie.\n",
        "\n",
        "The input layer will have X neurons, X equal to the number of movies ( $n$) in the datase. Each neuron will have a value of the normalized rating in range 0 to 1 with 0 meaning the user never rated the movie and 1 means the highest rating. The neuron in the visible layer will communicate with those in the hidden layer trying to learn latent factors and produce a generative model to make rating predictions.\n",
        "\n",
        "\n",
        "### RBM Neural Network Architecture\n",
        "\n",
        "For the RBM-based recommender we will use the rating matrix of the dimensions $m \\times n$. Here, $m$ is the number of users and $n$ is the number of movies. Each input $X$ that is passed to the input layer will have $n$ ratings ranging from 0 to 1. This means the input layer will have to have also $n$ neurons.\n",
        "\n",
        "The inputs are passed in batches of $k$ users and the network is trained for a specified number of epochs.\n",
        "\n",
        "We can design the hidden layer to have fewer nodes than $n$ thus forcing it to learn the most salient features and generalize better.\n",
        "\n",
        "The process starts with the input vector $v0$ that is passed to the visible layer. On its way to the hidden layer, the $v0$ vector is multiplied by the weights vector $W$. Additionally, a bias vector $hb$ is added guaranteeing that at least some neurons will fire. Before going through the activation function of the hidden layer the inputs then look like this:\n",
        "$$\n",
        "W*v0 + hb\n",
        "$$\n",
        "\n",
        "After the vector is passed through the activation function, we take a sample of them using what is called *Gibbs sampling*. This makes the RBM to produce the results stochastically which makes it more robust.\n",
        "\n",
        "The result of the sampling of the hidden layer output is marked $h0$ and is send in a *backward* pass to the visible layer. It is also multiplied by the same weights $W$ and a bias vector $vb$ is added at the visible layer. The ney input is therefore:\n",
        "\n",
        "$$\n",
        "W*h0 + vb\n",
        "$$\n",
        "\n",
        "This is then passes through the activation function of the visible layer, and is sampled using Gibbs sampling before going forward to the hidden layer in the next epoch.\n",
        "\n",
        "The RBM performs these back-and -forth passes several times learning the optimal weights that minimize the Kullback-Leibler distance between the original distribution and the learned probability distribution.\n",
        "\n",
        "\n",
        "### Build the Components of the RBM Class\n",
        "\n",
        "First, we need to specify the parameters to the RBM class. They are:\n",
        "\n",
        " - Input size\n",
        " - Output size\n",
        " - Learning rate\n",
        " - Number of epochs\n",
        " - Batch size that we will use during the training\n",
        " \n",
        "We will also create zero matrices for the weight matrix, hidden and visible bias vectors.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naw9qAee8aIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define RBM class\n",
        "class RBM(object):\n",
        "    \n",
        "    def __init__(self, input_size, output_size, \n",
        "                 learning_rate, epochs, batchsize):\n",
        "        # Define hyperparameters\n",
        "        self._input_size = input_size\n",
        "        self._output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batchsize = batchsize\n",
        "        \n",
        "        # Initialize weights and biases using zero matrices\n",
        "        self.w = np.zeros([input_size, output_size], dtype=np.float32)\n",
        "        self.hb = np.zeros([output_size], dtype=np.float32)\n",
        "        self.vb = np.zeros([input_size], dtype=np.float32)\n",
        "        \n",
        "    def prob_h_given_v(self, visible, w, hb):\n",
        "        ''' Forward pass: multiplying the visible input by weights and \n",
        "        adding the hidden bias vector\n",
        "        '''\n",
        "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
        "\n",
        "    def prob_v_given_h(self, hidden, w, vb):\n",
        "        '''Backward pass: multplying by weights and adding the visiblt\n",
        "        bias vector.'''\n",
        "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
        "    \n",
        "    def sample_prob(self, probs):\n",
        "        '''Perform Gibbs sampling\n",
        "        '''\n",
        "        return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
        "\n",
        "    def train(self, X):\n",
        "        # Placeholders for weight, hidden and visible bias vectors\n",
        "        _w = tf.placeholder(tf.float32, [self._input_size, self._output_size])\n",
        "        _hb = tf.placeholder(tf.float32, [self._output_size])\n",
        "        _vb = tf.placeholder(tf.float32, [self._input_size])\n",
        "        \n",
        "        # containers to keep values of previous and current \n",
        "        # weights and bias vectors\n",
        "        prv_w = np.zeros([self._input_size, self._output_size], dtype=np.float32)\n",
        "        prv_hb = np.zeros([self._output_size], dtype=np.float32)\n",
        "        prv_vb = np.zeros([self._input_size], dtype=np.float32)\n",
        "        \n",
        "        cur_w = np.zeros([self._input_size, self._output_size], dtype=np.float32)\n",
        "        cur_hb = np.zeros([self._output_size], dtype=np.float32)\n",
        "        cur_vb = np.zeros([self._input_size], dtype=np.float32)\n",
        "        \n",
        "        # Perform forward and backward passes\n",
        "        # note that the weights matrix is the same in the forward and backward\n",
        "        # passes\n",
        "        v0 = tf.placeholder(tf.float32, [None, self._input_size])\n",
        "        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb))\n",
        "        \n",
        "        # Perform the forward pass again\n",
        "        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))\n",
        "        h1 = self.prob_h_given_v(v1, _w, _hb)\n",
        "        \n",
        "        # update weights and bias vectors using Contrastive Divergence\n",
        "        positive_grad = tf.matmul(tf.transpose(v0), h0)\n",
        "        negative_grad = tf.matmul(tf.transpose(v1), h1)\n",
        "        \n",
        "        update_w = _w + self.learning_rate * \\\n",
        "            (positive_grad - negative_grad) / tf.to_float(tf.shape(v0)[0])\n",
        "        update_vb = _vb +  self.learning_rate * tf.reduce_mean(v0 - v1, 0)\n",
        "        update_hb = _hb +  self.learning_rate * tf.reduce_mean(h0 - h1, 0)\n",
        "        \n",
        "        # Error is defined as MSE\n",
        "        err = tf.reduce_mean(tf.square(v0 - v1))\n",
        "        \n",
        "        error_list = []\n",
        "        \n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            \n",
        "            for epoch in range(self.epochs):\n",
        "                for start, end in zip(range(0, len(X), \\\n",
        "                        self.batchsize),range(self.batchsize,len(X), \\\n",
        "                                              self.batchsize)):\n",
        "                    # the zip returns a tuple with start indicating\n",
        "                    # the beginning index of the batch, and end indicating\n",
        "                    # the end of the batch (start plus batch size)\n",
        "                    batch = X[start:end]\n",
        "                    cur_w = sess.run(update_w, feed_dict={v0: batch, \\\n",
        "                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
        "                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, \\\n",
        "                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
        "                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, \\\n",
        "                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
        "                    prv_w = cur_w\n",
        "                    prv_hb = cur_hb\n",
        "                    prv_vb = cur_vb\n",
        "                error = sess.run(err, feed_dict={v0: X, \\\n",
        "                                _w: cur_w, _vb: cur_vb, _hb: cur_hb})\n",
        "                print ('Epoch: %d' % epoch,'reconstruction error: %f' % error)\n",
        "                error_list.append(error)\n",
        "            self.w = prv_w\n",
        "            self.hb = prv_hb\n",
        "            self.vb = prv_vb\n",
        "            return error_list\n",
        "\n",
        "    def rbm_output(self, X):\n",
        "        \n",
        "        input_X = tf.constant(X)\n",
        "        _w = tf.constant(self.w)\n",
        "        _hb = tf.constant(self.hb)\n",
        "        _vb = tf.constant(self.vb)\n",
        "        out = tf.nn.sigmoid(tf.matmul(input_X, _w) + _hb)\n",
        "        hiddenGen = self.sample_prob(self.prob_h_given_v(input_X, _w, _hb))\n",
        "        visibleGen = self.sample_prob(self.prob_v_given_h(hiddenGen, _w, _vb))\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            return sess.run(out), sess.run(visibleGen), sess.run(hiddenGen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kCzR6Y6Ia0l",
        "colab_type": "text"
      },
      "source": [
        "### Train the RBM Recommender\n",
        "\n",
        "To train the recommneder we will generate an input array `inputX` from the `ratings_train` and convert its values to `float32`. Then we initialize an instance of the RBM class with the initial parameters like these:\n",
        "\n",
        " - input and output sizes: 1000\n",
        " - learning rate 0.3\n",
        " - epoch number 500\n",
        " - batch size: 200\n",
        " \n",
        "These parameter values can be experimented with to achieve better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFXqPPt8IA7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Begin the training cycle\n",
        "\n",
        "# Convert inputX into float32\n",
        "inputX = ratings_train\n",
        "inputX = inputX.astype(np.float32)\n",
        "\n",
        "# Define the parameters of the RBMs we will train\n",
        "rbm=RBM(1000,1000,1,1000,200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiDV_vABJdpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train RBM model\n",
        "err = rbm.train(inputX)\n",
        "outputX, reconstructedX, hiddenX = rbm.rbm_output(inputX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTkz6ni_Jgcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "9471a313-7673-4f60-c583-da2ba2012022"
      },
      "source": [
        "# Plot reconstruction errors\n",
        "pd.Series(err).plot(logy=False)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Reconstruction Error\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Reconstruction Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGM9ZsjHGGOO5/w8ZKfiKfwg/fgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPLqfEuLMFRu",
        "colab_type": "text"
      },
      "source": [
        "One can see that with longer training the reconstruction error decreases.\n",
        "\n",
        "Now, lets take the trained RMB to predict the ratings for users in the validation set (this one has the same users as the training set):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "talk9GrjMC3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict ratings for validation set\n",
        "inputValidation = ratings_validation\n",
        "inputValidation = inputValidation.astype(np.float32)\n",
        "\n",
        "finalOutput_validation, reconstructedOutput_validation, _ = \\\n",
        "    rbm.rbm_output(inputValidation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-F_Z9OBMaaP",
        "colab_type": "text"
      },
      "source": [
        "We will convert the predicstions into an array and calculate the MSE against the true validation ratings:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBAKgauOMYgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2aef9710-17c1-4ae6-b44f-e7210a55ef19"
      },
      "source": [
        "# Calculate MSE on validation set\n",
        "predictionsArray = reconstructedOutput_validation\n",
        "pred_validation = \\\n",
        "    predictionsArray[ratings_validation.nonzero()].flatten()\n",
        "actual_validation = \\\n",
        "    ratings_validation[ratings_validation.nonzero()].flatten()\n",
        "\n",
        "rbm_prediction = mean_squared_error(pred_validation, actual_validation)\n",
        "print('Mean squared error using RBM prediction:', rbm_prediction)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error using RBM prediction: 9.35618488140102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0-atMoWMn96",
        "colab_type": "text"
      },
      "source": [
        "We would need to perform more experiments to improve this initial error value.\n",
        "\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "We have used restricted Bolztmann machines to build a recommender hat tries to learn the distribution from the training data tp make predictions on the never before seen samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8zfo7uhMkki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}